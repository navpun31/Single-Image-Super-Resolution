{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from variables import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Models\n",
    "---\n",
    "### Generating LR, SR and HR images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Down-Sampling Function\n",
    "# TODO\n",
    "def downsample(image, sf = scaling_factor):\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-Process initial HR image\n",
    "# TODO\n",
    "def preprocess(image):\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading HR Images\n",
    "hr = {}\n",
    "for im in images:\n",
    "    path = path_images + im + '.png'\n",
    "    image = path # TODO - Load image\n",
    "    hr[im] = preprocess(image)\n",
    "    \n",
    "# { image_name : image }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating LR images\n",
    "lr = {name : downsample(image) for name, image in hr.items()}\n",
    "\n",
    "# { image_name : image }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting SR images\n",
    "sr = {}\n",
    "for model, predict in models.items():\n",
    "    sr_model = {}\n",
    "    for name, image in lr.items():\n",
    "        sr_model[name] = predict(image)\n",
    "    sr[model] = sr_model\n",
    "    \n",
    "# { model_name : { image_name : image } }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Models JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    results = {}\n",
    "    # { image_name : { metric : value } } - saved as model.json\n",
    "    \n",
    "    for name, image in sr[model].items():\n",
    "        metric_values = {}\n",
    "        for metric, func in metrics.items():\n",
    "            metric_values[metric] = func(image, hr[name])\n",
    "        \n",
    "        results[name] = metric_values\n",
    "    \n",
    "    path = path_model_results + model + '.json'\n",
    "    with open(path, 'w') as file:\n",
    "        json.dump(results, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Varying Scaling Factors for VDSR\n",
    "---\n",
    "### Generating LR, SR images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating LR images\n",
    "lr = {}\n",
    "for name, image in hr.items():\n",
    "    lr_images = {}\n",
    "    for sf in scaling_factors:\n",
    "        lr_images[sf] = downsample(image, sf)\n",
    "    lr[name] = lr_images\n",
    "    \n",
    "# { image_name : { scaling_factor : image } }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting SR images\n",
    "predict = models[scaling_model]\n",
    "sr = {}\n",
    "for name, lr_images in lr.items():\n",
    "    sr_images = {}\n",
    "    for sf, image in lr_images.items():\n",
    "        sr_images[sf] = predict(image)\n",
    "    sr[name] = sr_images\n",
    "\n",
    "# { image_name : { scaling_factor : image } }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling Factors JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, sr_images in sr.items():\n",
    "    results = {}\n",
    "    # { scaling_factor : { metric : value } } - saved as image.json\n",
    "    \n",
    "    for sf, image in sr_images.items():\n",
    "        metric_values = {}\n",
    "        for metric, func in metrics.items():\n",
    "            metric_values[metric] = func(image, hr[name])\n",
    "        \n",
    "        results[str(sf)] = metric_values\n",
    "    \n",
    "    path = path_scaling_results + name + '.json'\n",
    "    with open(path, 'w') as file:\n",
    "        json.dump(results, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VPython",
   "language": "python",
   "name": "vpython"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
